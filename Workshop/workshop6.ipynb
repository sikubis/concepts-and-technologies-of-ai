{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DifCBO9ZQI0i"
      },
      "outputs": [],
      "source": [
        "# 1. Implementing Sigmoid Function:\n",
        "# To Do Tasks\n",
        "\n",
        "import numpy as np\n",
        "def logistic_function(x):r\n",
        "    \"\"\"\n",
        "    Computes the logistic (sigmoid) function applied to any value of x.\n",
        "    Arguments:\n",
        "    x: scalar or numpy array of any size.\n",
        "    Returns:\n",
        "    y: logistic function applied to x.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    y = 1 / (1 + np.exp(-x))\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_function():\n",
        "  \"\"\"\n",
        "  Test cases for the logistic_function.\n",
        "  \"\"\"\n",
        "  # Test with scalar input\n",
        "  x_scalar = 0\n",
        "  expected_output_scalar = round(1 / (1 + np.exp(0)), 3) # Expected output: 0.5\n",
        "  assert round(logistic_function(x_scalar), 3) == expected_output_scalar, \"Test failed for scalar input\"\n",
        "  # Test with positive scalar input\n",
        "  x_pos = 2\n",
        "  expected_output_pos = round(1 / (1 + np.exp(-2)), 3) # Expected output: ~0.881\n",
        "  assert round(logistic_function(x_pos), 3) == expected_output_pos, \"Test failed for positive scalar input\"\n",
        "  # Test with negative scalar input\n",
        "  x_neg = -3\n",
        "  expected_output_neg = round(1 / (1 + np.exp(3)), 3) # Expected output: ~0.047\n",
        "  assert round(logistic_function(x_neg), 3) == expected_output_neg, \"Test failed for negative scalar input\"\n",
        "  # Test with numpy array input\n",
        "  x_array = np.array([0, 2, -3])\n",
        "  expected_output_array = np.array([0.5, 0.881, 0.047]) # Adjusted expected values rounded to 3 decimals\n",
        "  # Use np.round to round the array element-wise and compare\n",
        "  assert np.all(np.round(logistic_function(x_array), 3) == expected_output_array), \"Test failed for numpy array input\"\n",
        "  print(\"All tests passed!\")\n",
        "# Run the test case\n",
        "test_logistic_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fEfujAvRTce",
        "outputId": "f7748843-4748-41e6-fa1e-0fe89324da19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Implementing Log Loss Function:\n",
        "# To Do Tasks\n",
        "\n",
        "def log_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes log loss for true target value y ={0 or 1} and predicted target value yâ€™ inbetween {0-1}.\n",
        "    Arguments:\n",
        "    y_true (scalar): true target value {0 or 1}.\n",
        "    y_pred (scalar): predicted taget value {0-1}.\n",
        "    Returns:\n",
        "    loss (float): loss/error value\n",
        "    \"\"\"\n",
        "\n",
        "    import numpy as np\n",
        "    # Ensure y_pred is clipped to avoid log(0)\n",
        "    y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
        "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss\n",
        "\n",
        "# Test function:\n",
        "y_true, y_pred = 0, 0.1\n",
        "print(f'log loss({y_true}, {y_pred}) ==> {log_loss(y_true, y_pred)}')\n",
        "print(\"+++++++++++++--------------------------++++++++++++++++++++++++\")\n",
        "y_true, y_pred = 1, 0.9\n",
        "print(f'log loss({y_true}, {y_pred}) ==> {log_loss(y_true, y_pred)}')\n",
        "\n",
        "def test_log_loss():\n",
        "    \"\"\"\n",
        "    Test cases for the log_loss function.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    # Test case 1: Perfect prediction (y_true = 1, y_pred = 1)\n",
        "    y_true = 1\n",
        "    y_pred = 1\n",
        "    expected_loss = 0.0 # Log loss is 0 for perfect prediction\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected_loss), \"Test failed for perfect prediction (y_true=1, y_pred=1)\"\n",
        "    # Test case 2: Perfect prediction (y_true = 0, y_pred = 0)\n",
        "    y_true = 0\n",
        "    y_pred = 0\n",
        "    expected_loss = 0.0 # Log loss is 0 for perfect prediction\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected_loss), \"Test failed for perfect prediction (y_true=0, y_pred=0)\"\n",
        "    # Test case 3: Incorrect prediction (y_true = 1, y_pred = 0)\n",
        "    y_true = 1\n",
        "    y_pred = 0\n",
        "    try:\n",
        "        log_loss(y_true, y_pred) # This should raise an error due to log(0)\n",
        "    except ValueError:\n",
        "        pass # Test passed if ValueError is raised for log(0)\n",
        "    # Test case 4: Incorrect prediction (y_true = 0, y_pred = 1)\n",
        "    y_true = 0\n",
        "    y_pred = 1\n",
        "    try:\n",
        "        log_loss(y_true, y_pred) # This should raise an error due to log(0)\n",
        "    except ValueError:\n",
        "        pass # Test passed if ValueError is raised for log(0)\n",
        "    # Test case 5: Partially correct prediction\n",
        "    y_true = 1\n",
        "    y_pred = 0.8\n",
        "    expected_loss = -(1 * np.log(0.8)) - (0 * np.log(0.2)) # ~0.2231\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected_loss, atol=1e-6), \"Test failed for partially\\ncorrect prediction (y_true=1, y_pred=0.8)\"\n",
        "    y_true = 0\n",
        "    y_pred = 0.2\n",
        "    expected_loss = -(0 * np.log(0.2)) - (1 * np.log(0.8)) # ~0.2231\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected_loss, atol=1e-6), \"Test failed for partially\\ncorrect prediction (y_true=0, y_pred=0.2)\"\n",
        "    print(\"All tests passed!\")\n",
        "# Run the test case\n",
        "test_log_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7laPpCphXtU8",
        "outputId": "9258f431-2d43-42d6-e232-a0a84ba3f112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log loss(0, 0.1) ==> 0.10536051565782628\n",
            "+++++++++++++--------------------------++++++++++++++++++++++++\n",
            "log loss(1, 0.9) ==> 0.10536051565782628\n",
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Implementing Cost Function:\n",
        "# To Do Tasks\n",
        "\n",
        "def cost_function(y_true, y_pred):\n",
        "  \"\"\"\n",
        "    Computes log loss for inputs true value (0 or 1) and predicted value (between 0 and 1)\n",
        "    Args:\n",
        "      y_true (array_like, shape (n,)): array of true values (0 or 1)\n",
        "      y_pred (array_like, shape (n,)): array of predicted values (probability of y_pred being 1)\n",
        "    Returns:\n",
        "      cost (float): nonnegative cost corresponding to y_true and y_pred\n",
        "  \"\"\"\n",
        "  assert len(y_true) == len(y_pred), \"Length of true values and length of predicted values do not match\"\n",
        "  n = len(y_true)\n",
        "  loss_vec = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "  cost = np.sum(loss_vec) / n\n",
        "  return cost\n",
        "\n",
        "import numpy as np\n",
        "def test_cost_function():\n",
        "    # Test case 1: Simple example with known expected cost\n",
        "    y_true = np.array([1, 0, 1])\n",
        "    y_pred = np.array([0.9, 0.1, 0.8])\n",
        "    # Expected output: Manually calculate cost for these values\n",
        "    # log_loss(y_true, y_pred) for each example\n",
        "    expected_cost = (-(1 * np.log(0.9)) - (1 - 1) * np.log(1 - 0.9) +\n",
        "                   -(0 * np.log(0.1)) - (1 - 0) * np.log(1 - 0.1) +\n",
        "                   -(1 * np.log(0.8)) - (1 - 1) * np.log(1 - 0.8)) / 3\n",
        "    # Call the cost_function to get the result\n",
        "    result = cost_function(y_true, y_pred)\n",
        "    # Assert that the result is close to the expected cost with a tolerance of 1e-6\n",
        "    assert np.isclose(result, expected_cost, atol=1e-6), f\"Test failed: {result} != {expected_cost}\"\n",
        "    print(\"Test passed for simple case!\")\n",
        "# Run the test case\n",
        "test_cost_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMGAKG1BaOZc",
        "outputId": "ae33a39f-563f-41d3-a552-8cf47143bf01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed for simple case!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Extending the cost function for sigmoid regression to be used with model parameters.\n",
        "# To Do Tasks\n",
        "\n",
        "# Function to compute cost function in terms of model parameters - using vectorization\n",
        "def costfunction_logreg(X, y, w, b):\n",
        "  \"\"\"\n",
        "  Computes the cost function, given data and model parameters.\n",
        "  Args:\n",
        "    X (ndarray, shape (m,n)): data on features, m observations with n features.\n",
        "    y (array_like, shape (m,)): array of true values of target (0 or 1).\n",
        "    w (array_like, shape (n,)): weight parameters of the model.\n",
        "    b (float): bias parameter of the model.\n",
        "  Returns:\n",
        "    cost (float): nonnegative cost corresponding to y and y_pred.\n",
        "  \"\"\"\n",
        "  n, d = X.shape\n",
        "  assert len(y) == n, \"Number of feature observations and number of target observations do not match.\"\n",
        "  assert len(w) == d, \"Number of features and number of weight parameters do not match.\"\n",
        "  # Compute z using np.dot\n",
        "  z = np.dot(X, w) + b\n",
        "  # Compute predictions using logistic function (sigmoid)\n",
        "  y_pred = logistic_function(z)\n",
        "  # Compute the cost using the cost function\n",
        "  cost = cost_function(y, y_pred)\n",
        "  return cost\n",
        "# Testing the Function:\n",
        "X, y, w, b = np.array([[10, 20], [-10, 10]]), np.array([1, 0]), np.array([0.5, 1.5]), 1\n",
        "print(f\"cost for logistic regression(X = {X}, y = {y}, w = {w}, b = {b}) = {costfunction_logreg(X, y, w, b)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNvRHeohbZ08",
        "outputId": "8f88bfa9-2646-44a5-be90-daf505249ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost for logistic regression(X = [[ 10  20]\n",
            " [-10  10]], y = [1 0], w = [0.5 1.5], b = 1) = 5.500008350784906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Implementing Gradient Descent for Training Sigmoid Regression:\n",
        "# Task To Do\n",
        "\n",
        "def compute_gradient(X, y, w, b):\n",
        "  \"\"\"\n",
        "  Computes gradients of the cost function with respect to model parameters.\n",
        "  Args:\n",
        "    X (ndarray, shape (n,d)): Input data, n observations with d features\n",
        "    y (array_like, shape (n,)): True labels (0 or 1)\n",
        "    w (array_like, shape (d,)): Weight parameters of the model\n",
        "    b (float): Bias parameter of the model\n",
        "  Returns:\n",
        "    grad_w (array_like, shape (d,)): Gradients of the cost function with respect to the weight parameters\n",
        "    grad_b (float): Gradient of the cost function with respect to the bias parameter\n",
        "  \"\"\"\n",
        "  n, d = X.shape # X has shape (n, d)\n",
        "  assert len(y) == n, f\"Expected y to have {n} elements, but got {len(y)}\"\n",
        "  assert len(w) == d, f\"Expected w to have {d} elements, but got {len(w)}\"\n",
        "\n",
        "  # Compute predictions using logistic function (sigmoid)\n",
        "  y_pred = logistic_function(np.dot(X, w) + b)\n",
        "\n",
        "  # Compute gradients\n",
        "  grad_w = (1 / n) * np.dot(X.T, (y_pred - y))\n",
        "  grad_b = (1 / n) * np.sum(y_pred - y)\n",
        "\n",
        "  return grad_w, grad_b\n",
        "\n",
        "# Simple test case\n",
        "X = np.array([[10, 20], [-10, 10]]) # shape (2, 2)\n",
        "y = np.array([1, 0]) # shape (2,)\n",
        "w = np.array([0.5, 1.5]) # shape (2,)\n",
        "b = 1 # scalar\n",
        "# Assertion tests\n",
        "try:\n",
        "    grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "    print(\"Gradients computed successfully.\")\n",
        "    print(f\"grad_w: {grad_w}\")\n",
        "    print(f\"grad_b: {grad_b}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"Assertion error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48rRTBFtfzMJ",
        "outputId": "0e0536dd-ccc8-4148-dcfc-62d6793a3119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients computed successfully.\n",
            "grad_w: [-4.99991649  4.99991649]\n",
            "grad_b: 0.4999916492890759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 6. Gradient Descent for Sigmoid Regression:\n",
        "# Task To Do\n",
        "\n",
        "def gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False, show_params=True):\n",
        "  \"\"\"\n",
        "  Implements batch gradient descent to optimize logistic regression parameters.\n",
        "  Args:\n",
        "    X (ndarray, shape (n,d)): Data on features, n observations with d features\n",
        "    y (array_like, shape (n,)): True values of target (0 or 1)\n",
        "    w (array_like, shape (d,)): Initial weight parameters\n",
        "    b (float): Initial bias parameter\n",
        "    alpha (float): Learning rate\n",
        "    n_iter (int): Number of iterations\n",
        "    show_cost (bool): If True, displays cost every 100 iterations\n",
        "    show_params (bool): If True, displays parameters every 100 iterations\n",
        "  Returns:\n",
        "    w (array_like, shape (d,)): Optimized weight parameters\n",
        "    b (float): Optimized bias parameter\n",
        "    cost_history (list): List of cost values over iterations\n",
        "    params_history (list): List of parameters (w, b) over iterations\n",
        "  \"\"\"\n",
        "  n, d = X.shape\n",
        "  assert len(y) == n, \"Number of observations in X and y do not match\"\n",
        "  assert len(w) == d, \"Number of features in X and w do not match\"\n",
        "  cost_history = []\n",
        "  params_history = []\n",
        "  for i in range(n_iter):\n",
        "    # Compute gradients\n",
        "    grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "\n",
        "    # Update weights and bias\n",
        "    w -= alpha * grad_w\n",
        "    b -= alpha * grad_b\n",
        "\n",
        "    # Compute cost\n",
        "    cost = costfunction_logreg(X, y, w, b)\n",
        "\n",
        "    # Store cost and parameters\n",
        "    cost_history.append(cost)\n",
        "    params_history.append((w.copy(), b))\n",
        "\n",
        "    # Optionally print cost and parameters\n",
        "    if show_cost and (i % 100 == 0 or i == n_iter - 1):\n",
        "      print(f\"Iteration {i}: Cost = {cost:.6f}\")\n",
        "    if show_params and (i % 100 == 0 or i == n_iter - 1):\n",
        "      print(f\"Iteration {i}: w = {w}, b = {b:.6f}\")\n",
        "\n",
        "  return w, b, cost_history, params_history\n",
        "\n",
        "# Test the gradient_descent function with sample data\n",
        "X = np.array([[0.1, 0.2], [-0.1, 0.1]]) # Shape (2, 2)\n",
        "y = np.array([1, 0]) # Shape (2,)\n",
        "w = np.zeros(X.shape[1]) # Shape (2,) - same as number of features\n",
        "b = 0.0 # Scalar\n",
        "alpha = 0.1 # Learning rate\n",
        "n_iter = 100000 # Number of iterations\n",
        "# Perform gradient descent\n",
        "w_out, b_out, cost_history, params_history = gradient_descent(X, y, w, b, alpha, n_iter, show_cost=True, show_params=False)\n",
        "# Print final parameters and cost\n",
        "print(\"\\nFinal parameters:\")\n",
        "print(f\"w: {w_out}, b: {b_out}\")\n",
        "print(f\"Final cost: {cost_history[-1]:.6f}\")\n",
        "\n",
        "# Simple assertion test for gradient_descent\n",
        "def test_gradient_descent():\n",
        "  X = np.array([[0.1, 0.2], [-0.1, 0.1]]) # Shape (2, 2)\n",
        "  y = np.array([1, 0]) # Shape (2,)\n",
        "  w = np.zeros(X.shape[1]) # Shape (2,)\n",
        "  b = 0.0 # Scalar\n",
        "  alpha = 0.1 # Learning rate\n",
        "  n_iter = 100 # Number of iterations\n",
        "  # Run gradient descent\n",
        "  w_out, b_out, cost_history, _ = gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False, show_params=False)\n",
        "  # Assertions\n",
        "  assert len(cost_history) == n_iter, \"Cost history length does not match the number of iterations\"\n",
        "  assert w_out.shape == w.shape, \"Shape of output weights does not match the initial weights\"\n",
        "  assert isinstance(b_out, float), \"Bias output is not a float\"\n",
        "  assert cost_history[-1] < cost_history[0], \"Cost did not decrease over iterations\"\n",
        "  print(\"All tests passed!\")\n",
        "# Run the test\n",
        "test_gradient_descent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P02yhYx_ibaM",
        "outputId": "8c3a798f-440b-4c8d-8969-7815dcac4ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.692835\n",
            "Iteration 100: Cost = 0.662662\n",
            "Iteration 200: Cost = 0.634332\n",
            "Iteration 300: Cost = 0.607704\n",
            "Iteration 400: Cost = 0.582671\n",
            "Iteration 500: Cost = 0.559128\n",
            "Iteration 600: Cost = 0.536977\n",
            "Iteration 700: Cost = 0.516126\n",
            "Iteration 800: Cost = 0.496487\n",
            "Iteration 900: Cost = 0.477978\n",
            "Iteration 1000: Cost = 0.460524\n",
            "Iteration 1100: Cost = 0.444052\n",
            "Iteration 1200: Cost = 0.428497\n",
            "Iteration 1300: Cost = 0.413797\n",
            "Iteration 1400: Cost = 0.399895\n",
            "Iteration 1500: Cost = 0.386736\n",
            "Iteration 1600: Cost = 0.374272\n",
            "Iteration 1700: Cost = 0.362457\n",
            "Iteration 1800: Cost = 0.351248\n",
            "Iteration 1900: Cost = 0.340607\n",
            "Iteration 2000: Cost = 0.330495\n",
            "Iteration 2100: Cost = 0.320880\n",
            "Iteration 2200: Cost = 0.311730\n",
            "Iteration 2300: Cost = 0.303016\n",
            "Iteration 2400: Cost = 0.294710\n",
            "Iteration 2500: Cost = 0.286789\n",
            "Iteration 2600: Cost = 0.279228\n",
            "Iteration 2700: Cost = 0.272007\n",
            "Iteration 2800: Cost = 0.265104\n",
            "Iteration 2900: Cost = 0.258502\n",
            "Iteration 3000: Cost = 0.252182\n",
            "Iteration 3100: Cost = 0.246129\n",
            "Iteration 3200: Cost = 0.240328\n",
            "Iteration 3300: Cost = 0.234764\n",
            "Iteration 3400: Cost = 0.229425\n",
            "Iteration 3500: Cost = 0.224299\n",
            "Iteration 3600: Cost = 0.219373\n",
            "Iteration 3700: Cost = 0.214637\n",
            "Iteration 3800: Cost = 0.210081\n",
            "Iteration 3900: Cost = 0.205697\n",
            "Iteration 4000: Cost = 0.201474\n",
            "Iteration 4100: Cost = 0.197406\n",
            "Iteration 4200: Cost = 0.193484\n",
            "Iteration 4300: Cost = 0.189700\n",
            "Iteration 4400: Cost = 0.186049\n",
            "Iteration 4500: Cost = 0.182524\n",
            "Iteration 4600: Cost = 0.179119\n",
            "Iteration 4700: Cost = 0.175828\n",
            "Iteration 4800: Cost = 0.172646\n",
            "Iteration 4900: Cost = 0.169568\n",
            "Iteration 5000: Cost = 0.166589\n",
            "Iteration 5100: Cost = 0.163705\n",
            "Iteration 5200: Cost = 0.160912\n",
            "Iteration 5300: Cost = 0.158205\n",
            "Iteration 5400: Cost = 0.155581\n",
            "Iteration 5500: Cost = 0.153036\n",
            "Iteration 5600: Cost = 0.150568\n",
            "Iteration 5700: Cost = 0.148172\n",
            "Iteration 5800: Cost = 0.145846\n",
            "Iteration 5900: Cost = 0.143586\n",
            "Iteration 6000: Cost = 0.141392\n",
            "Iteration 6100: Cost = 0.139258\n",
            "Iteration 6200: Cost = 0.137184\n",
            "Iteration 6300: Cost = 0.135167\n",
            "Iteration 6400: Cost = 0.133205\n",
            "Iteration 6500: Cost = 0.131295\n",
            "Iteration 6600: Cost = 0.129436\n",
            "Iteration 6700: Cost = 0.127625\n",
            "Iteration 6800: Cost = 0.125862\n",
            "Iteration 6900: Cost = 0.124143\n",
            "Iteration 7000: Cost = 0.122469\n",
            "Iteration 7100: Cost = 0.120836\n",
            "Iteration 7200: Cost = 0.119243\n",
            "Iteration 7300: Cost = 0.117690\n",
            "Iteration 7400: Cost = 0.116175\n",
            "Iteration 7500: Cost = 0.114695\n",
            "Iteration 7600: Cost = 0.113251\n",
            "Iteration 7700: Cost = 0.111841\n",
            "Iteration 7800: Cost = 0.110464\n",
            "Iteration 7900: Cost = 0.109118\n",
            "Iteration 8000: Cost = 0.107804\n",
            "Iteration 8100: Cost = 0.106518\n",
            "Iteration 8200: Cost = 0.105262\n",
            "Iteration 8300: Cost = 0.104033\n",
            "Iteration 8400: Cost = 0.102832\n",
            "Iteration 8500: Cost = 0.101656\n",
            "Iteration 8600: Cost = 0.100506\n",
            "Iteration 8700: Cost = 0.099380\n",
            "Iteration 8800: Cost = 0.098278\n",
            "Iteration 8900: Cost = 0.097199\n",
            "Iteration 9000: Cost = 0.096142\n",
            "Iteration 9100: Cost = 0.095107\n",
            "Iteration 9200: Cost = 0.094093\n",
            "Iteration 9300: Cost = 0.093100\n",
            "Iteration 9400: Cost = 0.092126\n",
            "Iteration 9500: Cost = 0.091172\n",
            "Iteration 9600: Cost = 0.090236\n",
            "Iteration 9700: Cost = 0.089318\n",
            "Iteration 9800: Cost = 0.088418\n",
            "Iteration 9900: Cost = 0.087536\n",
            "Iteration 10000: Cost = 0.086670\n",
            "Iteration 10100: Cost = 0.085820\n",
            "Iteration 10200: Cost = 0.084986\n",
            "Iteration 10300: Cost = 0.084168\n",
            "Iteration 10400: Cost = 0.083364\n",
            "Iteration 10500: Cost = 0.082575\n",
            "Iteration 10600: Cost = 0.081800\n",
            "Iteration 10700: Cost = 0.081039\n",
            "Iteration 10800: Cost = 0.080292\n",
            "Iteration 10900: Cost = 0.079558\n",
            "Iteration 11000: Cost = 0.078836\n",
            "Iteration 11100: Cost = 0.078127\n",
            "Iteration 11200: Cost = 0.077430\n",
            "Iteration 11300: Cost = 0.076745\n",
            "Iteration 11400: Cost = 0.076072\n",
            "Iteration 11500: Cost = 0.075409\n",
            "Iteration 11600: Cost = 0.074758\n",
            "Iteration 11700: Cost = 0.074118\n",
            "Iteration 11800: Cost = 0.073488\n",
            "Iteration 11900: Cost = 0.072868\n",
            "Iteration 12000: Cost = 0.072259\n",
            "Iteration 12100: Cost = 0.071659\n",
            "Iteration 12200: Cost = 0.071068\n",
            "Iteration 12300: Cost = 0.070487\n",
            "Iteration 12400: Cost = 0.069915\n",
            "Iteration 12500: Cost = 0.069352\n",
            "Iteration 12600: Cost = 0.068798\n",
            "Iteration 12700: Cost = 0.068252\n",
            "Iteration 12800: Cost = 0.067714\n",
            "Iteration 12900: Cost = 0.067185\n",
            "Iteration 13000: Cost = 0.066663\n",
            "Iteration 13100: Cost = 0.066149\n",
            "Iteration 13200: Cost = 0.065643\n",
            "Iteration 13300: Cost = 0.065145\n",
            "Iteration 13400: Cost = 0.064653\n",
            "Iteration 13500: Cost = 0.064169\n",
            "Iteration 13600: Cost = 0.063692\n",
            "Iteration 13700: Cost = 0.063221\n",
            "Iteration 13800: Cost = 0.062757\n",
            "Iteration 13900: Cost = 0.062300\n",
            "Iteration 14000: Cost = 0.061849\n",
            "Iteration 14100: Cost = 0.061405\n",
            "Iteration 14200: Cost = 0.060966\n",
            "Iteration 14300: Cost = 0.060534\n",
            "Iteration 14400: Cost = 0.060108\n",
            "Iteration 14500: Cost = 0.059687\n",
            "Iteration 14600: Cost = 0.059272\n",
            "Iteration 14700: Cost = 0.058862\n",
            "Iteration 14800: Cost = 0.058459\n",
            "Iteration 14900: Cost = 0.058060\n",
            "Iteration 15000: Cost = 0.057667\n",
            "Iteration 15100: Cost = 0.057278\n",
            "Iteration 15200: Cost = 0.056895\n",
            "Iteration 15300: Cost = 0.056517\n",
            "Iteration 15400: Cost = 0.056144\n",
            "Iteration 15500: Cost = 0.055775\n",
            "Iteration 15600: Cost = 0.055411\n",
            "Iteration 15700: Cost = 0.055052\n",
            "Iteration 15800: Cost = 0.054697\n",
            "Iteration 15900: Cost = 0.054346\n",
            "Iteration 16000: Cost = 0.054000\n",
            "Iteration 16100: Cost = 0.053659\n",
            "Iteration 16200: Cost = 0.053321\n",
            "Iteration 16300: Cost = 0.052987\n",
            "Iteration 16400: Cost = 0.052658\n",
            "Iteration 16500: Cost = 0.052333\n",
            "Iteration 16600: Cost = 0.052011\n",
            "Iteration 16700: Cost = 0.051693\n",
            "Iteration 16800: Cost = 0.051379\n",
            "Iteration 16900: Cost = 0.051069\n",
            "Iteration 17000: Cost = 0.050762\n",
            "Iteration 17100: Cost = 0.050459\n",
            "Iteration 17200: Cost = 0.050159\n",
            "Iteration 17300: Cost = 0.049863\n",
            "Iteration 17400: Cost = 0.049571\n",
            "Iteration 17500: Cost = 0.049281\n",
            "Iteration 17600: Cost = 0.048995\n",
            "Iteration 17700: Cost = 0.048712\n",
            "Iteration 17800: Cost = 0.048432\n",
            "Iteration 17900: Cost = 0.048156\n",
            "Iteration 18000: Cost = 0.047882\n",
            "Iteration 18100: Cost = 0.047612\n",
            "Iteration 18200: Cost = 0.047344\n",
            "Iteration 18300: Cost = 0.047079\n",
            "Iteration 18400: Cost = 0.046818\n",
            "Iteration 18500: Cost = 0.046559\n",
            "Iteration 18600: Cost = 0.046302\n",
            "Iteration 18700: Cost = 0.046049\n",
            "Iteration 18800: Cost = 0.045798\n",
            "Iteration 18900: Cost = 0.045550\n",
            "Iteration 19000: Cost = 0.045305\n",
            "Iteration 19100: Cost = 0.045062\n",
            "Iteration 19200: Cost = 0.044822\n",
            "Iteration 19300: Cost = 0.044584\n",
            "Iteration 19400: Cost = 0.044348\n",
            "Iteration 19500: Cost = 0.044115\n",
            "Iteration 19600: Cost = 0.043885\n",
            "Iteration 19700: Cost = 0.043656\n",
            "Iteration 19800: Cost = 0.043430\n",
            "Iteration 19900: Cost = 0.043207\n",
            "Iteration 20000: Cost = 0.042985\n",
            "Iteration 20100: Cost = 0.042766\n",
            "Iteration 20200: Cost = 0.042549\n",
            "Iteration 20300: Cost = 0.042334\n",
            "Iteration 20400: Cost = 0.042121\n",
            "Iteration 20500: Cost = 0.041911\n",
            "Iteration 20600: Cost = 0.041702\n",
            "Iteration 20700: Cost = 0.041495\n",
            "Iteration 20800: Cost = 0.041291\n",
            "Iteration 20900: Cost = 0.041088\n",
            "Iteration 21000: Cost = 0.040888\n",
            "Iteration 21100: Cost = 0.040689\n",
            "Iteration 21200: Cost = 0.040492\n",
            "Iteration 21300: Cost = 0.040297\n",
            "Iteration 21400: Cost = 0.040104\n",
            "Iteration 21500: Cost = 0.039912\n",
            "Iteration 21600: Cost = 0.039722\n",
            "Iteration 21700: Cost = 0.039535\n",
            "Iteration 21800: Cost = 0.039348\n",
            "Iteration 21900: Cost = 0.039164\n",
            "Iteration 22000: Cost = 0.038981\n",
            "Iteration 22100: Cost = 0.038800\n",
            "Iteration 22200: Cost = 0.038621\n",
            "Iteration 22300: Cost = 0.038443\n",
            "Iteration 22400: Cost = 0.038267\n",
            "Iteration 22500: Cost = 0.038092\n",
            "Iteration 22600: Cost = 0.037919\n",
            "Iteration 22700: Cost = 0.037748\n",
            "Iteration 22800: Cost = 0.037577\n",
            "Iteration 22900: Cost = 0.037409\n",
            "Iteration 23000: Cost = 0.037242\n",
            "Iteration 23100: Cost = 0.037076\n",
            "Iteration 23200: Cost = 0.036912\n",
            "Iteration 23300: Cost = 0.036749\n",
            "Iteration 23400: Cost = 0.036588\n",
            "Iteration 23500: Cost = 0.036428\n",
            "Iteration 23600: Cost = 0.036270\n",
            "Iteration 23700: Cost = 0.036112\n",
            "Iteration 23800: Cost = 0.035956\n",
            "Iteration 23900: Cost = 0.035802\n",
            "Iteration 24000: Cost = 0.035649\n",
            "Iteration 24100: Cost = 0.035497\n",
            "Iteration 24200: Cost = 0.035346\n",
            "Iteration 24300: Cost = 0.035196\n",
            "Iteration 24400: Cost = 0.035048\n",
            "Iteration 24500: Cost = 0.034901\n",
            "Iteration 24600: Cost = 0.034755\n",
            "Iteration 24700: Cost = 0.034611\n",
            "Iteration 24800: Cost = 0.034467\n",
            "Iteration 24900: Cost = 0.034325\n",
            "Iteration 25000: Cost = 0.034184\n",
            "Iteration 25100: Cost = 0.034044\n",
            "Iteration 25200: Cost = 0.033905\n",
            "Iteration 25300: Cost = 0.033767\n",
            "Iteration 25400: Cost = 0.033631\n",
            "Iteration 25500: Cost = 0.033495\n",
            "Iteration 25600: Cost = 0.033361\n",
            "Iteration 25700: Cost = 0.033227\n",
            "Iteration 25800: Cost = 0.033095\n",
            "Iteration 25900: Cost = 0.032963\n",
            "Iteration 26000: Cost = 0.032833\n",
            "Iteration 26100: Cost = 0.032704\n",
            "Iteration 26200: Cost = 0.032575\n",
            "Iteration 26300: Cost = 0.032448\n",
            "Iteration 26400: Cost = 0.032322\n",
            "Iteration 26500: Cost = 0.032196\n",
            "Iteration 26600: Cost = 0.032072\n",
            "Iteration 26700: Cost = 0.031948\n",
            "Iteration 26800: Cost = 0.031826\n",
            "Iteration 26900: Cost = 0.031704\n",
            "Iteration 27000: Cost = 0.031583\n",
            "Iteration 27100: Cost = 0.031463\n",
            "Iteration 27200: Cost = 0.031344\n",
            "Iteration 27300: Cost = 0.031226\n",
            "Iteration 27400: Cost = 0.031109\n",
            "Iteration 27500: Cost = 0.030993\n",
            "Iteration 27600: Cost = 0.030877\n",
            "Iteration 27700: Cost = 0.030763\n",
            "Iteration 27800: Cost = 0.030649\n",
            "Iteration 27900: Cost = 0.030536\n",
            "Iteration 28000: Cost = 0.030424\n",
            "Iteration 28100: Cost = 0.030312\n",
            "Iteration 28200: Cost = 0.030202\n",
            "Iteration 28300: Cost = 0.030092\n",
            "Iteration 28400: Cost = 0.029983\n",
            "Iteration 28500: Cost = 0.029875\n",
            "Iteration 28600: Cost = 0.029768\n",
            "Iteration 28700: Cost = 0.029661\n",
            "Iteration 28800: Cost = 0.029555\n",
            "Iteration 28900: Cost = 0.029450\n",
            "Iteration 29000: Cost = 0.029345\n",
            "Iteration 29100: Cost = 0.029242\n",
            "Iteration 29200: Cost = 0.029139\n",
            "Iteration 29300: Cost = 0.029036\n",
            "Iteration 29400: Cost = 0.028935\n",
            "Iteration 29500: Cost = 0.028834\n",
            "Iteration 29600: Cost = 0.028734\n",
            "Iteration 29700: Cost = 0.028634\n",
            "Iteration 29800: Cost = 0.028535\n",
            "Iteration 29900: Cost = 0.028437\n",
            "Iteration 30000: Cost = 0.028340\n",
            "Iteration 30100: Cost = 0.028243\n",
            "Iteration 30200: Cost = 0.028147\n",
            "Iteration 30300: Cost = 0.028051\n",
            "Iteration 30400: Cost = 0.027956\n",
            "Iteration 30500: Cost = 0.027862\n",
            "Iteration 30600: Cost = 0.027768\n",
            "Iteration 30700: Cost = 0.027675\n",
            "Iteration 30800: Cost = 0.027583\n",
            "Iteration 30900: Cost = 0.027491\n",
            "Iteration 31000: Cost = 0.027400\n",
            "Iteration 31100: Cost = 0.027309\n",
            "Iteration 31200: Cost = 0.027219\n",
            "Iteration 31300: Cost = 0.027130\n",
            "Iteration 31400: Cost = 0.027041\n",
            "Iteration 31500: Cost = 0.026953\n",
            "Iteration 31600: Cost = 0.026865\n",
            "Iteration 31700: Cost = 0.026778\n",
            "Iteration 31800: Cost = 0.026691\n",
            "Iteration 31900: Cost = 0.026605\n",
            "Iteration 32000: Cost = 0.026519\n",
            "Iteration 32100: Cost = 0.026435\n",
            "Iteration 32200: Cost = 0.026350\n",
            "Iteration 32300: Cost = 0.026266\n",
            "Iteration 32400: Cost = 0.026183\n",
            "Iteration 32500: Cost = 0.026100\n",
            "Iteration 32600: Cost = 0.026018\n",
            "Iteration 32700: Cost = 0.025936\n",
            "Iteration 32800: Cost = 0.025854\n",
            "Iteration 32900: Cost = 0.025774\n",
            "Iteration 33000: Cost = 0.025693\n",
            "Iteration 33100: Cost = 0.025613\n",
            "Iteration 33200: Cost = 0.025534\n",
            "Iteration 33300: Cost = 0.025455\n",
            "Iteration 33400: Cost = 0.025377\n",
            "Iteration 33500: Cost = 0.025299\n",
            "Iteration 33600: Cost = 0.025222\n",
            "Iteration 33700: Cost = 0.025145\n",
            "Iteration 33800: Cost = 0.025068\n",
            "Iteration 33900: Cost = 0.024992\n",
            "Iteration 34000: Cost = 0.024916\n",
            "Iteration 34100: Cost = 0.024841\n",
            "Iteration 34200: Cost = 0.024767\n",
            "Iteration 34300: Cost = 0.024692\n",
            "Iteration 34400: Cost = 0.024619\n",
            "Iteration 34500: Cost = 0.024545\n",
            "Iteration 34600: Cost = 0.024472\n",
            "Iteration 34700: Cost = 0.024400\n",
            "Iteration 34800: Cost = 0.024328\n",
            "Iteration 34900: Cost = 0.024256\n",
            "Iteration 35000: Cost = 0.024185\n",
            "Iteration 35100: Cost = 0.024114\n",
            "Iteration 35200: Cost = 0.024043\n",
            "Iteration 35300: Cost = 0.023973\n",
            "Iteration 35400: Cost = 0.023904\n",
            "Iteration 35500: Cost = 0.023834\n",
            "Iteration 35600: Cost = 0.023766\n",
            "Iteration 35700: Cost = 0.023697\n",
            "Iteration 35800: Cost = 0.023629\n",
            "Iteration 35900: Cost = 0.023561\n",
            "Iteration 36000: Cost = 0.023494\n",
            "Iteration 36100: Cost = 0.023427\n",
            "Iteration 36200: Cost = 0.023361\n",
            "Iteration 36300: Cost = 0.023295\n",
            "Iteration 36400: Cost = 0.023229\n",
            "Iteration 36500: Cost = 0.023163\n",
            "Iteration 36600: Cost = 0.023098\n",
            "Iteration 36700: Cost = 0.023034\n",
            "Iteration 36800: Cost = 0.022969\n",
            "Iteration 36900: Cost = 0.022905\n",
            "Iteration 37000: Cost = 0.022842\n",
            "Iteration 37100: Cost = 0.022778\n",
            "Iteration 37200: Cost = 0.022715\n",
            "Iteration 37300: Cost = 0.022653\n",
            "Iteration 37400: Cost = 0.022590\n",
            "Iteration 37500: Cost = 0.022529\n",
            "Iteration 37600: Cost = 0.022467\n",
            "Iteration 37700: Cost = 0.022406\n",
            "Iteration 37800: Cost = 0.022345\n",
            "Iteration 37900: Cost = 0.022284\n",
            "Iteration 38000: Cost = 0.022224\n",
            "Iteration 38100: Cost = 0.022164\n",
            "Iteration 38200: Cost = 0.022104\n",
            "Iteration 38300: Cost = 0.022045\n",
            "Iteration 38400: Cost = 0.021986\n",
            "Iteration 38500: Cost = 0.021927\n",
            "Iteration 38600: Cost = 0.021869\n",
            "Iteration 38700: Cost = 0.021811\n",
            "Iteration 38800: Cost = 0.021753\n",
            "Iteration 38900: Cost = 0.021696\n",
            "Iteration 39000: Cost = 0.021638\n",
            "Iteration 39100: Cost = 0.021581\n",
            "Iteration 39200: Cost = 0.021525\n",
            "Iteration 39300: Cost = 0.021469\n",
            "Iteration 39400: Cost = 0.021413\n",
            "Iteration 39500: Cost = 0.021357\n",
            "Iteration 39600: Cost = 0.021301\n",
            "Iteration 39700: Cost = 0.021246\n",
            "Iteration 39800: Cost = 0.021191\n",
            "Iteration 39900: Cost = 0.021137\n",
            "Iteration 40000: Cost = 0.021083\n",
            "Iteration 40100: Cost = 0.021029\n",
            "Iteration 40200: Cost = 0.020975\n",
            "Iteration 40300: Cost = 0.020921\n",
            "Iteration 40400: Cost = 0.020868\n",
            "Iteration 40500: Cost = 0.020815\n",
            "Iteration 40600: Cost = 0.020762\n",
            "Iteration 40700: Cost = 0.020710\n",
            "Iteration 40800: Cost = 0.020658\n",
            "Iteration 40900: Cost = 0.020606\n",
            "Iteration 41000: Cost = 0.020554\n",
            "Iteration 41100: Cost = 0.020503\n",
            "Iteration 41200: Cost = 0.020452\n",
            "Iteration 41300: Cost = 0.020401\n",
            "Iteration 41400: Cost = 0.020350\n",
            "Iteration 41500: Cost = 0.020300\n",
            "Iteration 41600: Cost = 0.020250\n",
            "Iteration 41700: Cost = 0.020200\n",
            "Iteration 41800: Cost = 0.020150\n",
            "Iteration 41900: Cost = 0.020101\n",
            "Iteration 42000: Cost = 0.020052\n",
            "Iteration 42100: Cost = 0.020003\n",
            "Iteration 42200: Cost = 0.019954\n",
            "Iteration 42300: Cost = 0.019906\n",
            "Iteration 42400: Cost = 0.019857\n",
            "Iteration 42500: Cost = 0.019809\n",
            "Iteration 42600: Cost = 0.019762\n",
            "Iteration 42700: Cost = 0.019714\n",
            "Iteration 42800: Cost = 0.019667\n",
            "Iteration 42900: Cost = 0.019620\n",
            "Iteration 43000: Cost = 0.019573\n",
            "Iteration 43100: Cost = 0.019526\n",
            "Iteration 43200: Cost = 0.019480\n",
            "Iteration 43300: Cost = 0.019434\n",
            "Iteration 43400: Cost = 0.019388\n",
            "Iteration 43500: Cost = 0.019342\n",
            "Iteration 43600: Cost = 0.019296\n",
            "Iteration 43700: Cost = 0.019251\n",
            "Iteration 43800: Cost = 0.019206\n",
            "Iteration 43900: Cost = 0.019161\n",
            "Iteration 44000: Cost = 0.019116\n",
            "Iteration 44100: Cost = 0.019072\n",
            "Iteration 44200: Cost = 0.019027\n",
            "Iteration 44300: Cost = 0.018983\n",
            "Iteration 44400: Cost = 0.018939\n",
            "Iteration 44500: Cost = 0.018896\n",
            "Iteration 44600: Cost = 0.018852\n",
            "Iteration 44700: Cost = 0.018809\n",
            "Iteration 44800: Cost = 0.018766\n",
            "Iteration 44900: Cost = 0.018723\n",
            "Iteration 45000: Cost = 0.018680\n",
            "Iteration 45100: Cost = 0.018638\n",
            "Iteration 45200: Cost = 0.018595\n",
            "Iteration 45300: Cost = 0.018553\n",
            "Iteration 45400: Cost = 0.018511\n",
            "Iteration 45500: Cost = 0.018469\n",
            "Iteration 45600: Cost = 0.018428\n",
            "Iteration 45700: Cost = 0.018386\n",
            "Iteration 45800: Cost = 0.018345\n",
            "Iteration 45900: Cost = 0.018304\n",
            "Iteration 46000: Cost = 0.018263\n",
            "Iteration 46100: Cost = 0.018223\n",
            "Iteration 46200: Cost = 0.018182\n",
            "Iteration 46300: Cost = 0.018142\n",
            "Iteration 46400: Cost = 0.018102\n",
            "Iteration 46500: Cost = 0.018062\n",
            "Iteration 46600: Cost = 0.018022\n",
            "Iteration 46700: Cost = 0.017982\n",
            "Iteration 46800: Cost = 0.017943\n",
            "Iteration 46900: Cost = 0.017904\n",
            "Iteration 47000: Cost = 0.017864\n",
            "Iteration 47100: Cost = 0.017826\n",
            "Iteration 47200: Cost = 0.017787\n",
            "Iteration 47300: Cost = 0.017748\n",
            "Iteration 47400: Cost = 0.017710\n",
            "Iteration 47500: Cost = 0.017671\n",
            "Iteration 47600: Cost = 0.017633\n",
            "Iteration 47700: Cost = 0.017595\n",
            "Iteration 47800: Cost = 0.017558\n",
            "Iteration 47900: Cost = 0.017520\n",
            "Iteration 48000: Cost = 0.017483\n",
            "Iteration 48100: Cost = 0.017445\n",
            "Iteration 48200: Cost = 0.017408\n",
            "Iteration 48300: Cost = 0.017371\n",
            "Iteration 48400: Cost = 0.017334\n",
            "Iteration 48500: Cost = 0.017298\n",
            "Iteration 48600: Cost = 0.017261\n",
            "Iteration 48700: Cost = 0.017225\n",
            "Iteration 48800: Cost = 0.017189\n",
            "Iteration 48900: Cost = 0.017152\n",
            "Iteration 49000: Cost = 0.017117\n",
            "Iteration 49100: Cost = 0.017081\n",
            "Iteration 49200: Cost = 0.017045\n",
            "Iteration 49300: Cost = 0.017010\n",
            "Iteration 49400: Cost = 0.016974\n",
            "Iteration 49500: Cost = 0.016939\n",
            "Iteration 49600: Cost = 0.016904\n",
            "Iteration 49700: Cost = 0.016869\n",
            "Iteration 49800: Cost = 0.016834\n",
            "Iteration 49900: Cost = 0.016800\n",
            "Iteration 50000: Cost = 0.016765\n",
            "Iteration 50100: Cost = 0.016731\n",
            "Iteration 50200: Cost = 0.016697\n",
            "Iteration 50300: Cost = 0.016663\n",
            "Iteration 50400: Cost = 0.016629\n",
            "Iteration 50500: Cost = 0.016595\n",
            "Iteration 50600: Cost = 0.016561\n",
            "Iteration 50700: Cost = 0.016528\n",
            "Iteration 50800: Cost = 0.016495\n",
            "Iteration 50900: Cost = 0.016461\n",
            "Iteration 51000: Cost = 0.016428\n",
            "Iteration 51100: Cost = 0.016395\n",
            "Iteration 51200: Cost = 0.016362\n",
            "Iteration 51300: Cost = 0.016330\n",
            "Iteration 51400: Cost = 0.016297\n",
            "Iteration 51500: Cost = 0.016265\n",
            "Iteration 51600: Cost = 0.016232\n",
            "Iteration 51700: Cost = 0.016200\n",
            "Iteration 51800: Cost = 0.016168\n",
            "Iteration 51900: Cost = 0.016136\n",
            "Iteration 52000: Cost = 0.016104\n",
            "Iteration 52100: Cost = 0.016073\n",
            "Iteration 52200: Cost = 0.016041\n",
            "Iteration 52300: Cost = 0.016010\n",
            "Iteration 52400: Cost = 0.015978\n",
            "Iteration 52500: Cost = 0.015947\n",
            "Iteration 52600: Cost = 0.015916\n",
            "Iteration 52700: Cost = 0.015885\n",
            "Iteration 52800: Cost = 0.015854\n",
            "Iteration 52900: Cost = 0.015823\n",
            "Iteration 53000: Cost = 0.015793\n",
            "Iteration 53100: Cost = 0.015762\n",
            "Iteration 53200: Cost = 0.015732\n",
            "Iteration 53300: Cost = 0.015702\n",
            "Iteration 53400: Cost = 0.015672\n",
            "Iteration 53500: Cost = 0.015641\n",
            "Iteration 53600: Cost = 0.015612\n",
            "Iteration 53700: Cost = 0.015582\n",
            "Iteration 53800: Cost = 0.015552\n",
            "Iteration 53900: Cost = 0.015522\n",
            "Iteration 54000: Cost = 0.015493\n",
            "Iteration 54100: Cost = 0.015464\n",
            "Iteration 54200: Cost = 0.015434\n",
            "Iteration 54300: Cost = 0.015405\n",
            "Iteration 54400: Cost = 0.015376\n",
            "Iteration 54500: Cost = 0.015347\n",
            "Iteration 54600: Cost = 0.015318\n",
            "Iteration 54700: Cost = 0.015290\n",
            "Iteration 54800: Cost = 0.015261\n",
            "Iteration 54900: Cost = 0.015233\n",
            "Iteration 55000: Cost = 0.015204\n",
            "Iteration 55100: Cost = 0.015176\n",
            "Iteration 55200: Cost = 0.015148\n",
            "Iteration 55300: Cost = 0.015120\n",
            "Iteration 55400: Cost = 0.015092\n",
            "Iteration 55500: Cost = 0.015064\n",
            "Iteration 55600: Cost = 0.015036\n",
            "Iteration 55700: Cost = 0.015008\n",
            "Iteration 55800: Cost = 0.014981\n",
            "Iteration 55900: Cost = 0.014953\n",
            "Iteration 56000: Cost = 0.014926\n",
            "Iteration 56100: Cost = 0.014899\n",
            "Iteration 56200: Cost = 0.014872\n",
            "Iteration 56300: Cost = 0.014845\n",
            "Iteration 56400: Cost = 0.014818\n",
            "Iteration 56500: Cost = 0.014791\n",
            "Iteration 56600: Cost = 0.014764\n",
            "Iteration 56700: Cost = 0.014737\n",
            "Iteration 56800: Cost = 0.014711\n",
            "Iteration 56900: Cost = 0.014684\n",
            "Iteration 57000: Cost = 0.014658\n",
            "Iteration 57100: Cost = 0.014632\n",
            "Iteration 57200: Cost = 0.014605\n",
            "Iteration 57300: Cost = 0.014579\n",
            "Iteration 57400: Cost = 0.014553\n",
            "Iteration 57500: Cost = 0.014527\n",
            "Iteration 57600: Cost = 0.014501\n",
            "Iteration 57700: Cost = 0.014476\n",
            "Iteration 57800: Cost = 0.014450\n",
            "Iteration 57900: Cost = 0.014424\n",
            "Iteration 58000: Cost = 0.014399\n",
            "Iteration 58100: Cost = 0.014374\n",
            "Iteration 58200: Cost = 0.014348\n",
            "Iteration 58300: Cost = 0.014323\n",
            "Iteration 58400: Cost = 0.014298\n",
            "Iteration 58500: Cost = 0.014273\n",
            "Iteration 58600: Cost = 0.014248\n",
            "Iteration 58700: Cost = 0.014223\n",
            "Iteration 58800: Cost = 0.014198\n",
            "Iteration 58900: Cost = 0.014174\n",
            "Iteration 59000: Cost = 0.014149\n",
            "Iteration 59100: Cost = 0.014124\n",
            "Iteration 59200: Cost = 0.014100\n",
            "Iteration 59300: Cost = 0.014076\n",
            "Iteration 59400: Cost = 0.014051\n",
            "Iteration 59500: Cost = 0.014027\n",
            "Iteration 59600: Cost = 0.014003\n",
            "Iteration 59700: Cost = 0.013979\n",
            "Iteration 59800: Cost = 0.013955\n",
            "Iteration 59900: Cost = 0.013931\n",
            "Iteration 60000: Cost = 0.013907\n",
            "Iteration 60100: Cost = 0.013884\n",
            "Iteration 60200: Cost = 0.013860\n",
            "Iteration 60300: Cost = 0.013837\n",
            "Iteration 60400: Cost = 0.013813\n",
            "Iteration 60500: Cost = 0.013790\n",
            "Iteration 60600: Cost = 0.013766\n",
            "Iteration 60700: Cost = 0.013743\n",
            "Iteration 60800: Cost = 0.013720\n",
            "Iteration 60900: Cost = 0.013697\n",
            "Iteration 61000: Cost = 0.013674\n",
            "Iteration 61100: Cost = 0.013651\n",
            "Iteration 61200: Cost = 0.013628\n",
            "Iteration 61300: Cost = 0.013606\n",
            "Iteration 61400: Cost = 0.013583\n",
            "Iteration 61500: Cost = 0.013560\n",
            "Iteration 61600: Cost = 0.013538\n",
            "Iteration 61700: Cost = 0.013515\n",
            "Iteration 61800: Cost = 0.013493\n",
            "Iteration 61900: Cost = 0.013471\n",
            "Iteration 62000: Cost = 0.013448\n",
            "Iteration 62100: Cost = 0.013426\n",
            "Iteration 62200: Cost = 0.013404\n",
            "Iteration 62300: Cost = 0.013382\n",
            "Iteration 62400: Cost = 0.013360\n",
            "Iteration 62500: Cost = 0.013338\n",
            "Iteration 62600: Cost = 0.013316\n",
            "Iteration 62700: Cost = 0.013295\n",
            "Iteration 62800: Cost = 0.013273\n",
            "Iteration 62900: Cost = 0.013251\n",
            "Iteration 63000: Cost = 0.013230\n",
            "Iteration 63100: Cost = 0.013208\n",
            "Iteration 63200: Cost = 0.013187\n",
            "Iteration 63300: Cost = 0.013166\n",
            "Iteration 63400: Cost = 0.013144\n",
            "Iteration 63500: Cost = 0.013123\n",
            "Iteration 63600: Cost = 0.013102\n",
            "Iteration 63700: Cost = 0.013081\n",
            "Iteration 63800: Cost = 0.013060\n",
            "Iteration 63900: Cost = 0.013039\n",
            "Iteration 64000: Cost = 0.013018\n",
            "Iteration 64100: Cost = 0.012997\n",
            "Iteration 64200: Cost = 0.012977\n",
            "Iteration 64300: Cost = 0.012956\n",
            "Iteration 64400: Cost = 0.012935\n",
            "Iteration 64500: Cost = 0.012915\n",
            "Iteration 64600: Cost = 0.012895\n",
            "Iteration 64700: Cost = 0.012874\n",
            "Iteration 64800: Cost = 0.012854\n",
            "Iteration 64900: Cost = 0.012834\n",
            "Iteration 65000: Cost = 0.012813\n",
            "Iteration 65100: Cost = 0.012793\n",
            "Iteration 65200: Cost = 0.012773\n",
            "Iteration 65300: Cost = 0.012753\n",
            "Iteration 65400: Cost = 0.012733\n",
            "Iteration 65500: Cost = 0.012713\n",
            "Iteration 65600: Cost = 0.012693\n",
            "Iteration 65700: Cost = 0.012674\n",
            "Iteration 65800: Cost = 0.012654\n",
            "Iteration 65900: Cost = 0.012634\n",
            "Iteration 66000: Cost = 0.012615\n",
            "Iteration 66100: Cost = 0.012595\n",
            "Iteration 66200: Cost = 0.012576\n",
            "Iteration 66300: Cost = 0.012556\n",
            "Iteration 66400: Cost = 0.012537\n",
            "Iteration 66500: Cost = 0.012518\n",
            "Iteration 66600: Cost = 0.012498\n",
            "Iteration 66700: Cost = 0.012479\n",
            "Iteration 66800: Cost = 0.012460\n",
            "Iteration 66900: Cost = 0.012441\n",
            "Iteration 67000: Cost = 0.012422\n",
            "Iteration 67100: Cost = 0.012403\n",
            "Iteration 67200: Cost = 0.012384\n",
            "Iteration 67300: Cost = 0.012365\n",
            "Iteration 67400: Cost = 0.012347\n",
            "Iteration 67500: Cost = 0.012328\n",
            "Iteration 67600: Cost = 0.012309\n",
            "Iteration 67700: Cost = 0.012291\n",
            "Iteration 67800: Cost = 0.012272\n",
            "Iteration 67900: Cost = 0.012254\n",
            "Iteration 68000: Cost = 0.012235\n",
            "Iteration 68100: Cost = 0.012217\n",
            "Iteration 68200: Cost = 0.012199\n",
            "Iteration 68300: Cost = 0.012180\n",
            "Iteration 68400: Cost = 0.012162\n",
            "Iteration 68500: Cost = 0.012144\n",
            "Iteration 68600: Cost = 0.012126\n",
            "Iteration 68700: Cost = 0.012108\n",
            "Iteration 68800: Cost = 0.012090\n",
            "Iteration 68900: Cost = 0.012072\n",
            "Iteration 69000: Cost = 0.012054\n",
            "Iteration 69100: Cost = 0.012036\n",
            "Iteration 69200: Cost = 0.012018\n",
            "Iteration 69300: Cost = 0.012001\n",
            "Iteration 69400: Cost = 0.011983\n",
            "Iteration 69500: Cost = 0.011965\n",
            "Iteration 69600: Cost = 0.011948\n",
            "Iteration 69700: Cost = 0.011930\n",
            "Iteration 69800: Cost = 0.011913\n",
            "Iteration 69900: Cost = 0.011895\n",
            "Iteration 70000: Cost = 0.011878\n",
            "Iteration 70100: Cost = 0.011861\n",
            "Iteration 70200: Cost = 0.011843\n",
            "Iteration 70300: Cost = 0.011826\n",
            "Iteration 70400: Cost = 0.011809\n",
            "Iteration 70500: Cost = 0.011792\n",
            "Iteration 70600: Cost = 0.011775\n",
            "Iteration 70700: Cost = 0.011758\n",
            "Iteration 70800: Cost = 0.011741\n",
            "Iteration 70900: Cost = 0.011724\n",
            "Iteration 71000: Cost = 0.011707\n",
            "Iteration 71100: Cost = 0.011690\n",
            "Iteration 71200: Cost = 0.011673\n",
            "Iteration 71300: Cost = 0.011656\n",
            "Iteration 71400: Cost = 0.011640\n",
            "Iteration 71500: Cost = 0.011623\n",
            "Iteration 71600: Cost = 0.011607\n",
            "Iteration 71700: Cost = 0.011590\n",
            "Iteration 71800: Cost = 0.011574\n",
            "Iteration 71900: Cost = 0.011557\n",
            "Iteration 72000: Cost = 0.011541\n",
            "Iteration 72100: Cost = 0.011524\n",
            "Iteration 72200: Cost = 0.011508\n",
            "Iteration 72300: Cost = 0.011492\n",
            "Iteration 72400: Cost = 0.011475\n",
            "Iteration 72500: Cost = 0.011459\n",
            "Iteration 72600: Cost = 0.011443\n",
            "Iteration 72700: Cost = 0.011427\n",
            "Iteration 72800: Cost = 0.011411\n",
            "Iteration 72900: Cost = 0.011395\n",
            "Iteration 73000: Cost = 0.011379\n",
            "Iteration 73100: Cost = 0.011363\n",
            "Iteration 73200: Cost = 0.011347\n",
            "Iteration 73300: Cost = 0.011331\n",
            "Iteration 73400: Cost = 0.011316\n",
            "Iteration 73500: Cost = 0.011300\n",
            "Iteration 73600: Cost = 0.011284\n",
            "Iteration 73700: Cost = 0.011269\n",
            "Iteration 73800: Cost = 0.011253\n",
            "Iteration 73900: Cost = 0.011237\n",
            "Iteration 74000: Cost = 0.011222\n",
            "Iteration 74100: Cost = 0.011206\n",
            "Iteration 74200: Cost = 0.011191\n",
            "Iteration 74300: Cost = 0.011176\n",
            "Iteration 74400: Cost = 0.011160\n",
            "Iteration 74500: Cost = 0.011145\n",
            "Iteration 74600: Cost = 0.011130\n",
            "Iteration 74700: Cost = 0.011114\n",
            "Iteration 74800: Cost = 0.011099\n",
            "Iteration 74900: Cost = 0.011084\n",
            "Iteration 75000: Cost = 0.011069\n",
            "Iteration 75100: Cost = 0.011054\n",
            "Iteration 75200: Cost = 0.011039\n",
            "Iteration 75300: Cost = 0.011024\n",
            "Iteration 75400: Cost = 0.011009\n",
            "Iteration 75500: Cost = 0.010994\n",
            "Iteration 75600: Cost = 0.010979\n",
            "Iteration 75700: Cost = 0.010964\n",
            "Iteration 75800: Cost = 0.010950\n",
            "Iteration 75900: Cost = 0.010935\n",
            "Iteration 76000: Cost = 0.010920\n",
            "Iteration 76100: Cost = 0.010906\n",
            "Iteration 76200: Cost = 0.010891\n",
            "Iteration 76300: Cost = 0.010876\n",
            "Iteration 76400: Cost = 0.010862\n",
            "Iteration 76500: Cost = 0.010847\n",
            "Iteration 76600: Cost = 0.010833\n",
            "Iteration 76700: Cost = 0.010818\n",
            "Iteration 76800: Cost = 0.010804\n",
            "Iteration 76900: Cost = 0.010790\n",
            "Iteration 77000: Cost = 0.010775\n",
            "Iteration 77100: Cost = 0.010761\n",
            "Iteration 77200: Cost = 0.010747\n",
            "Iteration 77300: Cost = 0.010733\n",
            "Iteration 77400: Cost = 0.010719\n",
            "Iteration 77500: Cost = 0.010704\n",
            "Iteration 77600: Cost = 0.010690\n",
            "Iteration 77700: Cost = 0.010676\n",
            "Iteration 77800: Cost = 0.010662\n",
            "Iteration 77900: Cost = 0.010648\n",
            "Iteration 78000: Cost = 0.010634\n",
            "Iteration 78100: Cost = 0.010620\n",
            "Iteration 78200: Cost = 0.010607\n",
            "Iteration 78300: Cost = 0.010593\n",
            "Iteration 78400: Cost = 0.010579\n",
            "Iteration 78500: Cost = 0.010565\n",
            "Iteration 78600: Cost = 0.010551\n",
            "Iteration 78700: Cost = 0.010538\n",
            "Iteration 78800: Cost = 0.010524\n",
            "Iteration 78900: Cost = 0.010510\n",
            "Iteration 79000: Cost = 0.010497\n",
            "Iteration 79100: Cost = 0.010483\n",
            "Iteration 79200: Cost = 0.010470\n",
            "Iteration 79300: Cost = 0.010456\n",
            "Iteration 79400: Cost = 0.010443\n",
            "Iteration 79500: Cost = 0.010429\n",
            "Iteration 79600: Cost = 0.010416\n",
            "Iteration 79700: Cost = 0.010403\n",
            "Iteration 79800: Cost = 0.010389\n",
            "Iteration 79900: Cost = 0.010376\n",
            "Iteration 80000: Cost = 0.010363\n",
            "Iteration 80100: Cost = 0.010350\n",
            "Iteration 80200: Cost = 0.010337\n",
            "Iteration 80300: Cost = 0.010323\n",
            "Iteration 80400: Cost = 0.010310\n",
            "Iteration 80500: Cost = 0.010297\n",
            "Iteration 80600: Cost = 0.010284\n",
            "Iteration 80700: Cost = 0.010271\n",
            "Iteration 80800: Cost = 0.010258\n",
            "Iteration 80900: Cost = 0.010245\n",
            "Iteration 81000: Cost = 0.010232\n",
            "Iteration 81100: Cost = 0.010219\n",
            "Iteration 81200: Cost = 0.010207\n",
            "Iteration 81300: Cost = 0.010194\n",
            "Iteration 81400: Cost = 0.010181\n",
            "Iteration 81500: Cost = 0.010168\n",
            "Iteration 81600: Cost = 0.010155\n",
            "Iteration 81700: Cost = 0.010143\n",
            "Iteration 81800: Cost = 0.010130\n",
            "Iteration 81900: Cost = 0.010117\n",
            "Iteration 82000: Cost = 0.010105\n",
            "Iteration 82100: Cost = 0.010092\n",
            "Iteration 82200: Cost = 0.010080\n",
            "Iteration 82300: Cost = 0.010067\n",
            "Iteration 82400: Cost = 0.010055\n",
            "Iteration 82500: Cost = 0.010042\n",
            "Iteration 82600: Cost = 0.010030\n",
            "Iteration 82700: Cost = 0.010018\n",
            "Iteration 82800: Cost = 0.010005\n",
            "Iteration 82900: Cost = 0.009993\n",
            "Iteration 83000: Cost = 0.009981\n",
            "Iteration 83100: Cost = 0.009968\n",
            "Iteration 83200: Cost = 0.009956\n",
            "Iteration 83300: Cost = 0.009944\n",
            "Iteration 83400: Cost = 0.009932\n",
            "Iteration 83500: Cost = 0.009920\n",
            "Iteration 83600: Cost = 0.009908\n",
            "Iteration 83700: Cost = 0.009895\n",
            "Iteration 83800: Cost = 0.009883\n",
            "Iteration 83900: Cost = 0.009871\n",
            "Iteration 84000: Cost = 0.009859\n",
            "Iteration 84100: Cost = 0.009847\n",
            "Iteration 84200: Cost = 0.009835\n",
            "Iteration 84300: Cost = 0.009824\n",
            "Iteration 84400: Cost = 0.009812\n",
            "Iteration 84500: Cost = 0.009800\n",
            "Iteration 84600: Cost = 0.009788\n",
            "Iteration 84700: Cost = 0.009776\n",
            "Iteration 84800: Cost = 0.009764\n",
            "Iteration 84900: Cost = 0.009753\n",
            "Iteration 85000: Cost = 0.009741\n",
            "Iteration 85100: Cost = 0.009729\n",
            "Iteration 85200: Cost = 0.009718\n",
            "Iteration 85300: Cost = 0.009706\n",
            "Iteration 85400: Cost = 0.009694\n",
            "Iteration 85500: Cost = 0.009683\n",
            "Iteration 85600: Cost = 0.009671\n",
            "Iteration 85700: Cost = 0.009660\n",
            "Iteration 85800: Cost = 0.009648\n",
            "Iteration 85900: Cost = 0.009637\n",
            "Iteration 86000: Cost = 0.009625\n",
            "Iteration 86100: Cost = 0.009614\n",
            "Iteration 86200: Cost = 0.009603\n",
            "Iteration 86300: Cost = 0.009591\n",
            "Iteration 86400: Cost = 0.009580\n",
            "Iteration 86500: Cost = 0.009569\n",
            "Iteration 86600: Cost = 0.009557\n",
            "Iteration 86700: Cost = 0.009546\n",
            "Iteration 86800: Cost = 0.009535\n",
            "Iteration 86900: Cost = 0.009524\n",
            "Iteration 87000: Cost = 0.009513\n",
            "Iteration 87100: Cost = 0.009501\n",
            "Iteration 87200: Cost = 0.009490\n",
            "Iteration 87300: Cost = 0.009479\n",
            "Iteration 87400: Cost = 0.009468\n",
            "Iteration 87500: Cost = 0.009457\n",
            "Iteration 87600: Cost = 0.009446\n",
            "Iteration 87700: Cost = 0.009435\n",
            "Iteration 87800: Cost = 0.009424\n",
            "Iteration 87900: Cost = 0.009413\n",
            "Iteration 88000: Cost = 0.009402\n",
            "Iteration 88100: Cost = 0.009391\n",
            "Iteration 88200: Cost = 0.009381\n",
            "Iteration 88300: Cost = 0.009370\n",
            "Iteration 88400: Cost = 0.009359\n",
            "Iteration 88500: Cost = 0.009348\n",
            "Iteration 88600: Cost = 0.009337\n",
            "Iteration 88700: Cost = 0.009327\n",
            "Iteration 88800: Cost = 0.009316\n",
            "Iteration 88900: Cost = 0.009305\n",
            "Iteration 89000: Cost = 0.009295\n",
            "Iteration 89100: Cost = 0.009284\n",
            "Iteration 89200: Cost = 0.009273\n",
            "Iteration 89300: Cost = 0.009263\n",
            "Iteration 89400: Cost = 0.009252\n",
            "Iteration 89500: Cost = 0.009242\n",
            "Iteration 89600: Cost = 0.009231\n",
            "Iteration 89700: Cost = 0.009221\n",
            "Iteration 89800: Cost = 0.009210\n",
            "Iteration 89900: Cost = 0.009200\n",
            "Iteration 90000: Cost = 0.009189\n",
            "Iteration 90100: Cost = 0.009179\n",
            "Iteration 90200: Cost = 0.009168\n",
            "Iteration 90300: Cost = 0.009158\n",
            "Iteration 90400: Cost = 0.009148\n",
            "Iteration 90500: Cost = 0.009138\n",
            "Iteration 90600: Cost = 0.009127\n",
            "Iteration 90700: Cost = 0.009117\n",
            "Iteration 90800: Cost = 0.009107\n",
            "Iteration 90900: Cost = 0.009096\n",
            "Iteration 91000: Cost = 0.009086\n",
            "Iteration 91100: Cost = 0.009076\n",
            "Iteration 91200: Cost = 0.009066\n",
            "Iteration 91300: Cost = 0.009056\n",
            "Iteration 91400: Cost = 0.009046\n",
            "Iteration 91500: Cost = 0.009036\n",
            "Iteration 91600: Cost = 0.009026\n",
            "Iteration 91700: Cost = 0.009016\n",
            "Iteration 91800: Cost = 0.009006\n",
            "Iteration 91900: Cost = 0.008996\n",
            "Iteration 92000: Cost = 0.008986\n",
            "Iteration 92100: Cost = 0.008976\n",
            "Iteration 92200: Cost = 0.008966\n",
            "Iteration 92300: Cost = 0.008956\n",
            "Iteration 92400: Cost = 0.008946\n",
            "Iteration 92500: Cost = 0.008936\n",
            "Iteration 92600: Cost = 0.008926\n",
            "Iteration 92700: Cost = 0.008916\n",
            "Iteration 92800: Cost = 0.008907\n",
            "Iteration 92900: Cost = 0.008897\n",
            "Iteration 93000: Cost = 0.008887\n",
            "Iteration 93100: Cost = 0.008877\n",
            "Iteration 93200: Cost = 0.008868\n",
            "Iteration 93300: Cost = 0.008858\n",
            "Iteration 93400: Cost = 0.008848\n",
            "Iteration 93500: Cost = 0.008839\n",
            "Iteration 93600: Cost = 0.008829\n",
            "Iteration 93700: Cost = 0.008819\n",
            "Iteration 93800: Cost = 0.008810\n",
            "Iteration 93900: Cost = 0.008800\n",
            "Iteration 94000: Cost = 0.008791\n",
            "Iteration 94100: Cost = 0.008781\n",
            "Iteration 94200: Cost = 0.008772\n",
            "Iteration 94300: Cost = 0.008762\n",
            "Iteration 94400: Cost = 0.008753\n",
            "Iteration 94500: Cost = 0.008743\n",
            "Iteration 94600: Cost = 0.008734\n",
            "Iteration 94700: Cost = 0.008725\n",
            "Iteration 94800: Cost = 0.008715\n",
            "Iteration 94900: Cost = 0.008706\n",
            "Iteration 95000: Cost = 0.008696\n",
            "Iteration 95100: Cost = 0.008687\n",
            "Iteration 95200: Cost = 0.008678\n",
            "Iteration 95300: Cost = 0.008669\n",
            "Iteration 95400: Cost = 0.008659\n",
            "Iteration 95500: Cost = 0.008650\n",
            "Iteration 95600: Cost = 0.008641\n",
            "Iteration 95700: Cost = 0.008632\n",
            "Iteration 95800: Cost = 0.008622\n",
            "Iteration 95900: Cost = 0.008613\n",
            "Iteration 96000: Cost = 0.008604\n",
            "Iteration 96100: Cost = 0.008595\n",
            "Iteration 96200: Cost = 0.008586\n",
            "Iteration 96300: Cost = 0.008577\n",
            "Iteration 96400: Cost = 0.008568\n",
            "Iteration 96500: Cost = 0.008559\n",
            "Iteration 96600: Cost = 0.008550\n",
            "Iteration 96700: Cost = 0.008541\n",
            "Iteration 96800: Cost = 0.008532\n",
            "Iteration 96900: Cost = 0.008523\n",
            "Iteration 97000: Cost = 0.008514\n",
            "Iteration 97100: Cost = 0.008505\n",
            "Iteration 97200: Cost = 0.008496\n",
            "Iteration 97300: Cost = 0.008487\n",
            "Iteration 97400: Cost = 0.008478\n",
            "Iteration 97500: Cost = 0.008469\n",
            "Iteration 97600: Cost = 0.008460\n",
            "Iteration 97700: Cost = 0.008452\n",
            "Iteration 97800: Cost = 0.008443\n",
            "Iteration 97900: Cost = 0.008434\n",
            "Iteration 98000: Cost = 0.008425\n",
            "Iteration 98100: Cost = 0.008416\n",
            "Iteration 98200: Cost = 0.008408\n",
            "Iteration 98300: Cost = 0.008399\n",
            "Iteration 98400: Cost = 0.008390\n",
            "Iteration 98500: Cost = 0.008382\n",
            "Iteration 98600: Cost = 0.008373\n",
            "Iteration 98700: Cost = 0.008364\n",
            "Iteration 98800: Cost = 0.008356\n",
            "Iteration 98900: Cost = 0.008347\n",
            "Iteration 99000: Cost = 0.008339\n",
            "Iteration 99100: Cost = 0.008330\n",
            "Iteration 99200: Cost = 0.008321\n",
            "Iteration 99300: Cost = 0.008313\n",
            "Iteration 99400: Cost = 0.008304\n",
            "Iteration 99500: Cost = 0.008296\n",
            "Iteration 99600: Cost = 0.008287\n",
            "Iteration 99700: Cost = 0.008279\n",
            "Iteration 99800: Cost = 0.008270\n",
            "Iteration 99900: Cost = 0.008262\n",
            "Iteration 99999: Cost = 0.008254\n",
            "\n",
            "Final parameters:\n",
            "w: [38.51304248 18.83386869], b: -2.8176836626325836\n",
            "Final cost: 0.008254\n",
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Decision/Prediction Function for Binary Classification:\n",
        "# Task To Do\n",
        "\n",
        "import numpy as np\n",
        "def prediction(X, w, b, threshold=0.5):\n",
        "  \"\"\"\n",
        "  Predicts binary outcomes for given input features based on logistic regression parameters.\n",
        "  Arguments:\n",
        "    X (ndarray, shape (n,d)): Array of test independent variables (features) with n samples and d features.\n",
        "    w (ndarray, shape (d,)): Array of weights learned via gradient descent.\n",
        "    b (float): Bias learned via gradient descent.\n",
        "    threshold (float, optional): Classification threshold for predicting class labels. Default is 0.5.\n",
        "  Returns:\n",
        "    y_pred (ndarray, shape (n,)): Array of predicted dependent variable (binary class labels: 0 or 1).\n",
        "  \"\"\"\n",
        "  # Compute the predicted probabilities using the logistic function\n",
        "  y_test_prob = logistic_function(np.dot(X, w) + b)\n",
        "  # Classify based on the threshold\n",
        "  y_pred = (y_test_prob >= threshold).astype(int)\n",
        "  return y_pred\n",
        "\n",
        "def test_prediction():\n",
        "  X_test = np.array([[0.5, 1.0], [1.5, -0.5], [-0.5, -1.0]]) # Shape (3, 2)\n",
        "  w_test = np.array([1.0, -1.0]) # Shape (2,)\n",
        "  b_test = 0.0 # Scalar bias\n",
        "  threshold = 0.5 # Default threshold\n",
        "  # Updated expected output\n",
        "  expected_output = np.array([0, 1, 1])\n",
        "  # Call the prediction function\n",
        "  y_pred = prediction(X_test, w_test, b_test, threshold)\n",
        "  # Assert that the output matches the expected output\n",
        "  assert np.array_equal(y_pred, expected_output), f\"Expected {expected_output}, but got {y_pred}\"\n",
        "  print(\"Test passed!\")\n",
        "test_prediction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8uQ5klJc5Pj",
        "outputId": "3532932d-7450-4ad5-a108-510f51734827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Evaluating Classifier:\n",
        "# Task To Do\n",
        "\n",
        "def evaluate_classification(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Computes the confusion matrix, precision, recall, and F1-score for binary classification.\n",
        "  Arguments:\n",
        "    y_true (ndarray, shape (n,)): Ground truth binary labels (0 or 1).\n",
        "    y_pred (ndarray, shape (n,)): Predicted binary labels (0 or 1).\n",
        "  Returns:\n",
        "    metrics (dict): A dictionary containing confusion matrix, precision, recall, and F1-score.\n",
        "  \"\"\"\n",
        "  # Initialize confusion matrix components\n",
        "  TP = np.sum((y_true == 1) & (y_pred == 1)) # True Positives\n",
        "  TN = np.sum((y_true == 0) & (y_pred == 0)) # True Negatives\n",
        "  FP = np.sum((y_true == 0) & (y_pred == 1)) # False Positives\n",
        "  FN = np.sum((y_true == 1) & (y_pred == 0)) # False Negatives\n",
        "  # Confusion matrix\n",
        "  confusion_matrix = np.array([[TN, FP],\n",
        "                              [FN, TP]])\n",
        "  # Precision, recall, and F1-score\n",
        "  precision = TP / (TP + FP) if (TP + FP) > 0.0 else 0.0\n",
        "  recall = TP / (TP + FN) if (TP + FN) > 0.0 else 0.0\n",
        "  f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0.0 else 0.0\n",
        "  # Metrics dictionary\n",
        "  metrics = {\n",
        "    \"confusion_matrix\": confusion_matrix,\n",
        "    \"precision\": precision,\n",
        "    \"recall\": recall,\n",
        "    \"f1_score\": f1_score\n",
        "  }\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "nHGxThvCf7l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJ2frx8ohDG0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}